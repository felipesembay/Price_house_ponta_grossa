# Projeto de Machine Learning: PrevisÃ£o de PreÃ§os de ImÃ³veis em Ponta Grossa

Um projeto end-to-end de machine learning que utiliza regressÃ£o para prever o preÃ§o de imÃ³veis em Ponta Grossa, PR, com dados coletados via web scraping do ZapImÃ³veis.

## ğŸ“‹ Estrutura do Projeto

```
Casas Ponta Grossa/
â”œâ”€â”€ src/                          # CÃ³digo-fonte principal
â”‚   â”œâ”€â”€ scraper.py               # Web scraping do ZapImÃ³veis
â”‚   â”œâ”€â”€ preprocessing.py          # Limpeza e preparaÃ§Ã£o de dados
â”‚   â””â”€â”€ modelo.py                # Treino e avaliaÃ§Ã£o de modelos
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                     # Dados brutos (nÃ£o rastreados)
â”‚   â””â”€â”€ processed/               # Dados processados (nÃ£o rastreados)
â”œâ”€â”€ models/                       # Modelos treinados (nÃ£o rastreados)
â”œâ”€â”€ notebooks/                    # Jupyter notebooks para exploraÃ§Ã£o
â”œâ”€â”€ requirements.txt             # DependÃªncias do projeto
â”œâ”€â”€ .gitignore                   # Arquivos ignorados pelo Git
â””â”€â”€ README.md                    # Este arquivo
```

## ğŸ› ï¸ DependÃªncias

- **requests**: Para requisiÃ§Ãµes HTTP
- **beautifulsoup4**: Para parsing de HTML
- **pandas**: ManipulaÃ§Ã£o de dados
- **numpy**: OperaÃ§Ãµes numÃ©ricas
- **scikit-learn**: Machine learning
- **matplotlib/seaborn**: VisualizaÃ§Ã£o

## ğŸš€ Como Usar

### 1. Configurar Ambiente

```bash
# Criar ambiente virtual
python -m venv venv
source venv/bin/activate  # No Windows: venv\Scripts\activate

# Instalar dependÃªncias
pip install -r requirements.txt
```

### 2. Fazer Web Scraping

```bash
python src/scraper.py
```

Isso irÃ¡:
- Fazer scraping de mÃºltiplas pÃ¡ginas do ZapImÃ³veis
- Extrair dados como preÃ§o, localizaÃ§Ã£o, quartos, banheiros e Ã¡rea
- Salvar dados brutos em `data/raw/imoveis_guarapuava.csv`

### 3. PrÃ©-processar Dados

```bash
python src/preprocessing.py
```

OperaÃ§Ãµes realizadas:
- Limpeza de valores monetÃ¡rios
- Tratamento de valores faltantes
- RemoÃ§Ã£o de outliers
- Feature engineering (preÃ§o por mÂ², etc.)
- NormalizaÃ§Ã£o

SaÃ­da: `data/processed/imoveis_guarapuava_processados.csv`

### 4. Treinar Modelos

```bash
python src/modelo.py
```

Modelos treinados:
- RegressÃ£o Linear
- Ridge (L2 Regularization)
- Lasso (L1 Regularization)
- Random Forest
- Gradient Boosting

SaÃ­da:
- Melhor modelo salvo em `models/`
- Comparativo de mÃ©tricas em `results/comparativo_modelos.csv`

## ğŸ“Š MÃ©tricas de AvaliaÃ§Ã£o

Os modelos sÃ£o avaliados usando:
- **RMSE** (Root Mean Squared Error): Erro mÃ©dio em reais
- **MAE** (Mean Absolute Error): Erro absoluto mÃ©dio
- **RÂ² Score**: ProporÃ§Ã£o da variÃ¢ncia explicada (0-1)

## ğŸ” Features Utilizadas

| Feature | DescriÃ§Ã£o |
|---------|-----------|
| `area_m2` | Ãrea do imÃ³vel em metros quadrados |
| `quartos` | NÃºmero de quartos |
| `banheiros` | NÃºmero de banheiros |
| `preco_por_m2` | PreÃ§o por metro quadrado (engenharia) |
| `banheiro_por_quarto` | RazÃ£o banheiros/quartos (engenharia) |
| `tamanho_imovel` | ClassificaÃ§Ã£o de tamanho (engenharia) |

## ğŸ“ˆ Pipeline Completo

```
Web Scraping â†’ Limpeza â†’ ExploraÃ§Ã£o â†’ PrÃ©-processamento â†’ 
Feature Engineering â†’ Treinamento â†’ AvaliaÃ§Ã£o â†’ Deployment
```

## ğŸ¯ PrÃ³ximos Passos

1. **ExploraÃ§Ã£o de Dados**: Criar notebooks Jupyter para anÃ¡lise exploratÃ³ria
2. **Ajuste de HiperparÃ¢metros**: OtimizaÃ§Ã£o usando GridSearchCV
3. **ValidaÃ§Ã£o Cruzada**: Implementar k-fold cross-validation
4. **API**: Criar API REST para fazer prediÃ§Ãµes
5. **Monitoramento**: Acompanhar performance do modelo em produÃ§Ã£o

## âš ï¸ Importante

- Respeite o `robots.txt` e os termos de serviÃ§o do ZapImÃ³veis
- Use delays adequados entre requisiÃ§Ãµes (padrÃ£o: 2 segundos)
- Os dados brutos e modelos nÃ£o sÃ£o rastreados no Git (veja `.gitignore`)

## ğŸ“ LicenÃ§a

Este projeto Ã© fornecido como exemplo educacional.

## ğŸ‘¤ Autor

Felipe - Portfolio de Machine Learning

---

**Ãšltima atualizaÃ§Ã£o**: 6 de fevereiro de 2026
